# -*- coding: utf-8 -*-
"""BARAKA SALEH BIN TAYEB,TP084082.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b-yWOhysoFCXyA368xOipQpsryh5-K_B

## Creating a Balanced Subset (10,400 Samples) from the A‚ÄìZ Handwritten Alphabets Dataset
"""

import pandas as pd

# Load the dataset
df = pd.read_csv("A_Z Handwritten Data.csv")

# Check dataset info
print("Total samples:", len(df))
print("Number of unique labels:", df['0'].nunique())

# Choose how many samples per letter
# 400 per letter = 26 √ó 400 = 10,400 samples
samples_per_letter = 400

# Balanced sampling
balanced_df = (
    df.groupby('0')
      .apply(lambda x: x.sample(n=samples_per_letter, random_state=42))
      .reset_index(drop=True)
)

# Save the balanced dataset
balanced_df.to_csv("A_Z_handwritten_balanced.csv", index=False)

print("Balanced dataset saved as A_Z_handwritten_balanced (1).csv")
print("Balanced dataset size:", len(balanced_df))

"""We created a balanced subset from the A‚ÄìZ Handwritten Alphabets dataset by selecting an equal number of samples for each letter. Since the original dataset contained over 370,000 samples with 26 unique labels, we decided to extract 400 samples per letter to ensure uniform representation across all classes. This process resulted in a balanced dataset of 10,400 samples in total (26 √ó 400). By applying stratified random sampling with a fixed random state, we maintained fairness and reproducibility in the subset, which helps reduce bias during training and ensures that each alphabet character contributes equally to the model learning process.

## Import Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

"""## Set seeds for reproducibility"""

import numpy as np, random, tensorflow as tf

SEED = 42
np.random.seed(SEED)
random.seed(SEED)
tf.random.set_seed(SEED)

"""## Load dataset and inspect shape"""

csv_path = "/content/A_Z_handwritten_balanced (1).csv"
df = pd.read_csv(csv_path)


df.head()

"""This code loads the balanced A‚ÄìZ handwritten dataset from a CSV file and displays the first few rows. It helps verify that the dataset has been read correctly and that the structure matches expectations

## Check shape
"""

# Check shape
print("Shape:", df.shape)

# The first column is the label (0‚Äì25), the rest are 784 pixels
X = df.drop('0', axis=1).values   # image pixels
y = df['0'].values                # labels

"""This step prints the dataset‚Äôs shape to confirm the number of rows (samples) and columns (features). It also separates the features (image pixels) from the labels (class IDs 0‚Äì25)

## Dataset Information
"""

# Check data types and missing values
df.info()

# Check if any missing values
print("Missing values:\n", df.isnull().sum().sum())

"""Here, the code checks the dataset‚Äôs data types and ensures there are no missing values. This is an important quality check before training

## Separate Features and Labels
"""

# First column is the label (0-25 for A-Z)
y = df.iloc[:, 0].astype(int).values
X = df.iloc[:, 1:].values

print("Feature shape:", X.shape)
print("Label shape:", y.shape)

"""This line explicitly assigns the first column as the labels and the rest as pixel values. The conversion to integers ensures the labels are in the correct format

## Check label distribution
"""

plt.figure(figsize=(10, 5))
sns.countplot(x=y, palette="viridis")
plt.title("Distribution of Handwritten Alphabets (A‚ÄìZ)")
plt.xlabel("Label (0 = A, 25 = Z)")
plt.ylabel("Count")
plt.show()

# map 0‚Äì25 -> 'A'‚Äì'Z' for reference
id2char = {i: chr(ord('A')+i) for i in range(26)}
print({k:id2char[k] for k in range(26)})

"""The code plots a histogram showing the distribution of samples across all 26 classes. This helps confirm the dataset is balanced after sampling

## Preview some images
"""

def show_samples(X_flat, y, n=12):
    idx = np.random.choice(len(X_flat), n, replace=False)
    imgs = X_flat[idx].reshape(-1, 28, 28)
    labs = y[idx]

    cols = 6
    rows = int(np.ceil(n/cols))
    plt.figure(figsize=(2.2*cols, 2.2*rows))
    for i, (img, lab) in enumerate(zip(imgs, labs), 1):
        plt.subplot(rows, cols, i)
        plt.imshow(img, cmap="gray")
        plt.title(f"{lab} ({id2char[lab]})", fontsize=9)
        plt.axis("off")
    plt.tight_layout()
    plt.show()

show_samples(X, y, n=12)

"""This function randomly selects and displays handwritten characters with their labels. It provides a quick visual check that the data is correctly structured

## Basic pixel intensity statistics
"""

pixels = X
print("Pixel Min:", pixels.min(), "Pixel Max:", pixels.max(), "Mean:", pixels.mean())

plt.figure(figsize=(8,4))
plt.hist(pixels.ravel(), bins=25)   # no custom colors; keep defaults
plt.title("Pixel Intensity Distribution")
plt.xlabel("Pixel value (0‚Äì255)")
plt.ylabel("Frequency")
plt.show()

"""This prints the min, max, and mean pixel values, followed by a histogram of pixel intensity distribution. It helps confirm the grayscale pixel range (0‚Äì255)

## Normalize
"""

X = X.astype("float32") / 255.0
print("After normalization ‚Äî min/max:", float(X.min()), float(X.max()))

"""This scales all pixel values from [0‚Äì255] to [0‚Äì1], which speeds up training and stabilizes learning in neural networks

## Train/Validation/Test split (stratified)
"""

from sklearn.model_selection import train_test_split

RNG_SEED = 42

# 80% train, 20% temp
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.20, stratify=y, random_state=RNG_SEED
)

# 10% val, 10% test
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=RNG_SEED
)

print("Train:", X_train.shape, y_train.shape)
print("Val:  ", X_val.shape,   y_val.shape)
print("Test: ", X_test.shape,  y_test.shape)

"""The dataset is split into 80% training, 10% validation, and 10% test sets using stratified sampling. This ensures each class is equally represented in all subsets

## One-Hot Encode Labels
"""

from tensorflow.keras.utils import to_categorical

num_classes = len(set(y))
y_train_oh = to_categorical(y_train, num_classes)
y_val_oh   = to_categorical(y_val,   num_classes)
y_test_oh  = to_categorical(y_test,  num_classes)

print("One-hot label shapes:")
print("Train:", y_train_oh.shape)
print("Val:  ", y_val_oh.shape)
print("Test: ", y_test_oh.shape)

"""This converts integer labels into one-hot encoded vectors, making them suitable for categorical classification tasks in deep learning models

## Reshape for CNN
"""

# CNN expects (28, 28, 1) shape
X_train_cnn = X_train.reshape(-1, 28, 28, 1)
X_val_cnn   = X_val.reshape(-1, 28, 28, 1)
X_test_cnn  = X_test.reshape(-1, 28, 28, 1)

print("CNN input shapes:")
print("Train:", X_train_cnn.shape)
print("Val:  ", X_val_cnn.shape)
print("Test: ", X_test_cnn.shape)

"""The input images are reshaped into 28√ó28√ó1 format, which matches the expected input shape for convolutional neural networks

## Data Augmentation
"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# ‚úÖ Safe augmentations for alphabets
train_aug = ImageDataGenerator(
    rotation_range=20,            # ‚â§ ¬±20¬∞
    width_shift_range=0.10,       # ‚â§ 10%
    height_shift_range=0.10,      # ‚â§ 10%
    zoom_range=0.10,              # ‚â§ 10%
    fill_mode="nearest"
)
plain_gen = ImageDataGenerator()

BATCH_SIZE = 64
train_gen = train_aug.flow(X_train_cnn, y_train_oh, batch_size=BATCH_SIZE, shuffle=True, seed=SEED)
val_gen   = plain_gen.flow(X_val_cnn,   y_val_oh,   batch_size=BATCH_SIZE, shuffle=False)
test_gen  = plain_gen.flow(X_test_cnn,  y_test_oh,  batch_size=BATCH_SIZE, shuffle=False)

"""Data augmentation creates slightly modified versions of training images by applying rotations, shifts, and zoom. This improves generalization by preventing overfitting

## 1. Basic 3-layer CNN
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.optimizers import Adam

# ============================
# MODEL DEFINITION (Basic CNN)
# ============================
model = Sequential()

# Layer 1: Conv + MaxPooling
model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(28, 28, 1)))
model.add(MaxPooling2D(pool_size=(2,2)))

# Layer 2: Conv + MaxPooling
model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

# Layer 3: Conv (No Pooling here ‚Äî optional)
model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu'))

# Flatten and Fully Connected Layers
model.add(Flatten())
model.add(Dense(128, activation='relu'))     # Optional fully connected layer
model.add(Dense(26, activation='softmax'))   # Output: 26 classes (A‚ÄìZ)

"""## Compile the Model"""

model.compile(optimizer=Adam(),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Show model summary
model.summary()

"""## Train the Model"""

history = model.fit(X_train_cnn, y_train_oh,
                    validation_data=(X_val_cnn, y_val_oh),
                    epochs=20,
                    batch_size=64,
                    verbose=1)

"""## Evaluate on test set"""

# --- evaluate on test set ---
test_loss, test_acc = model.evaluate(X_test_cnn, y_test_oh, verbose=0)
print(f"Test accuracy: {test_acc:.4f}")

"""## Plots (learning curves)"""

# Plot accuracy and loss from training history
def plot_history(history):
    plt.figure(figsize=(12, 5))

    # Accuracy plot
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Val Accuracy')
    plt.title('Model Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    # Loss plot
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.tight_layout()
    plt.show()

# Call the function
plot_history(history)

"""## classification report and confusion matrix"""

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
import seaborn as sns

# Predict classes from test set
y_pred = model.predict(X_test_cnn)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test_oh, axis=1)

# Classification report
print("Classification Report:")
print(classification_report(y_true, y_pred_classes))

# Confusion matrix
cm = confusion_matrix(y_true, y_pred_classes)

# Plot confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

"""The model consists of three convolutional layers with ReLU activation, max-pooling layers, and a fully connected dense layer before the softmax output. It was compiled with Adam optimizer and trained for 20 epochs.
Result: The basic CNN achieved good accuracy on the validation and test sets, showing that even a simple architecture can effectively recognize handwritten alphabets. However, slight overfitting was observed as training accuracy was higher than validation accuracy

## 2. Regularized CNN
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import EarlyStopping

model = Sequential([
    # Block 1
    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),
    MaxPooling2D((2,2)),
    Dropout(0.25),

    # Block 2
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D((2,2)),
    Dropout(0.25),

    # Block 3
    Conv2D(128, (3,3), activation='relu'),
    Dropout(0.25),

    Flatten(),
    Dense(128, activation='relu', kernel_regularizer=l2(1e-4)),
    Dropout(0.5),
    Dense(26, activation='softmax')
])

model.compile(
    optimizer=Adam(learning_rate=1e-3),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

early_stop = EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True
)

history = model.fit(
    X_train_cnn, y_train_oh,
    validation_data=(X_val_cnn, y_val_oh),
    epochs=60,
    batch_size=64,
    callbacks=[early_stop],
    verbose=1
)

# Evaluate on test set
test_loss, test_acc = model.evaluate(X_test_cnn, y_test_oh, verbose=0)
print(f"Test accuracy: {test_acc:.4f}")

# Plot accuracy and loss from training history
def plot_history(history):
    plt.figure(figsize=(12, 5))

    # Accuracy plot
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Val Accuracy')
    plt.title('Model Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    # Loss plot
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.tight_layout()
    plt.show()

# Call the function
plot_history(history)

"""## Classification Report and confusion matrix"""

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
import seaborn as sns

# Predict classes from test set
y_pred = model.predict(X_test_cnn)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test_oh, axis=1)

# Classification report
print("Classification Report:")
print(classification_report(y_true, y_pred_classes))

# Confusion matrix
cm = confusion_matrix(y_true, y_pred_classes)

# Plot confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

"""This model introduced dropout layers and L2 regularization to reduce overfitting. Early stopping was also applied to stop training once validation loss stopped improving.
Result: Compared to the baseline CNN, this model showed better generalization, achieving higher validation accuracy and reduced overfitting. The dropout and regularization techniques clearly improved model stability

## 3.The Hyperparameter tuning for ‚Äúthe Regularized CNN‚Äù
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, BatchNormalization
from tensorflow.keras.layers import GlobalAveragePooling2D
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import Adam

def build_regularized_model(hp):
    model = Sequential()

    # Block 1
    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
    model.add(BatchNormalization())
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(hp.Float('dropout1', 0.3, 0.5, step=0.05)))

    # Block 2
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(hp.Float('dropout2', 0.3, 0.5, step=0.05)))

    # Block 3
    model.add(Conv2D(128, (3, 3), activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(hp.Float('dropout3', 0.3, 0.5, step=0.05)))


    model.add(GlobalAveragePooling2D())

    # Dense layer with L2 regularization
    model.add(Dense(
        units=hp.Int('dense_units', min_value=64, max_value=128, step=64),
        activation='relu',
        kernel_regularizer=l2(hp.Choice('l2_strength', values=[1e-3, 1e-4]))
    ))
    model.add(Dropout(hp.Float('dropout_fc', 0.4, 0.6, step=0.1)))

    # Output layer
    model.add(Dense(26, activation='softmax'))

    # Compile
    model.compile(
        optimizer=Adam(learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    return model

tuner = kt.RandomSearch(
    build_regularized_model,
    objective='val_accuracy',
    max_trials=10,
    directory='my_tuner_dir',
    project_name='regularized_model3'
)

from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# Define callbacks
early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)

# Launch the tuner search
tuner.search(
    X_train_cnn, y_train_oh, # Use the preprocessed training data directly
    validation_data=(X_val_cnn, y_val_oh),
    epochs=40,
    callbacks=[early_stop, reduce_lr],
    verbose=1
)

import matplotlib.pyplot as plt

# Get best model & hyperparameters
best_model = tuner.get_best_models(1)[0]
best_hps   = tuner.get_best_hyperparameters(1)[0]

print("‚úÖ Best Hyperparameters Found:")
for param in ['learning_rate', 'dropout1', 'dropout2', 'dropout3', 'dense_units', 'dropout_fc', 'l2_strength']:
    print(f"{param}: {best_hps.get(param)}")

# Retrain best model
history = best_model.fit(
    X_train_cnn, y_train_oh,
    validation_data=(X_val_cnn, y_val_oh),
    epochs=40,
    callbacks=[early_stop, reduce_lr],
    verbose=1
)

# Save best model
best_model.save("best_cnn_model_v4.keras")

# üìä Plot accuracy & loss
plt.figure(figsize=(14,5))

# Accuracy plot
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title("Model Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()

# Loss plot
plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title("Model Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()

plt.show()

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

# --- Get predictions
y_pred = []
y_true = []

for images, labels in test_ds:
    preds = model.predict(images)
    y_pred.extend(np.argmax(preds, axis=1))
    y_true.extend(labels.numpy())

# --- Confusion matrix
cm = confusion_matrix(y_true, y_pred)
labels = [chr(i) for i in range(65, 91)]  # A‚ÄìZ

plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix ‚Äî A‚ÄìZ Classification')
plt.show()

# --- Classification report
print("Classification Report:\n")
print(classification_report(y_true, y_pred, target_names=labels))

"""Using Keras Tuner, the model searched for optimal values for dropout rates, dense units, learning rates, and L2 strength. The best hyperparameters were then used to rebuild and retrain the CNN.
Result: The tuned CNN achieved better validation accuracy than the manually regularized CNN. However, the improvement was moderate, and the gains were mostly from fine-tuning dropout and learning rate values

## 4. Rebuilt Best CNN (from tuning)
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, BatchNormalization, GlobalAveragePooling2D
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau # Import necessary callbacks

# üîÅ Rebuild model using best hyperparameters
model = Sequential()

# Block 1
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.3))

# Block 2
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.3))

# Block 3
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.45))

# Global Average Pooling
model.add(GlobalAveragePooling2D())

# Dense Layer with L2 regularization
model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.0001)))
model.add(Dropout(0.5))

# Output layer
model.add(Dense(26, activation='softmax'))

# Compile with best learning rate
model.compile(
    optimizer=Adam(learning_rate=0.01),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Define the callbacks
early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)

"""## Train It Again"""

history = model.fit(
    X_train_cnn, y_train_oh,
    validation_data=(X_val_cnn, y_val_oh),
    epochs=40,
    callbacks=[early_stop, reduce_lr],
    verbose=1
)

"""## Save the Model"""

model.save("rebuilt_best_model.keras")

"""## Plot Accuracy & Loss"""

import matplotlib.pyplot as plt

plt.figure(figsize=(14, 5))

# Accuracy Plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Loss Plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

"""## Classification Report + Confusion Matrix"""

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Step 1: Predict on validation set
y_pred_probs = model.predict(X_val_cnn)
y_pred = np.argmax(y_pred_probs, axis=1)
y_true = np.argmax(y_val_oh, axis=1)

# Step 2: Classification Report
print("üìã Classification Report:")
print(classification_report(y_true, y_pred, digits=4))

# Step 3: Confusion Matrix
cm = confusion_matrix(y_true, y_pred)

# Step 4: Plot Confusion Matrix
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=list(range(26)), yticklabels=list(range(26)))
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

"""The best CNN model was reconstructed with the chosen hyperparameters and retrained. Global Average Pooling replaced Flatten, and dropout was carefully applied.
Result: This rebuilt model reached strong validation accuracy and stable training performance. It outperformed the baseline and regularized CNN, making it the best-performing CNN variant in this experiment

## Test the model in rendom sample
"""

import numpy as np
import matplotlib.pyplot as plt

# Pick 5 random samples from validation set
num_samples = 5
random_indices = np.random.choice(X_val_cnn.shape[0], num_samples, replace=False)

for i in random_indices:
    image = X_val_cnn[i]
    true_label = np.argmax(y_val_oh[i])  # from one-hot to number

    # Predict
    prediction = model.predict(np.expand_dims(image, axis=0))  # shape: (1, 28, 28, 1)
    predicted_label = np.argmax(prediction)

    # Show result
    plt.imshow(image.squeeze(), cmap='gray')
    plt.title(f"True: {true_label} | Predicted: {predicted_label}")
    plt.axis('off')
    plt.show()

model.save("cnn_model.keras")

"""##5. MobileNetV2 (Frozen Baseline ‚Äì Transfer Learning)"""

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint  # ‚úÖ add ModelCheckpoint
from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input as mb_pre

# 1) Mixed precision = lower memory (only if you have GPU)
try:
    from tensorflow.keras import mixed_precision
    mixed_precision.set_global_policy("mixed_float16")
except Exception:
    pass

NUM_CLASSES = 26
TARGET = 96  # small = stable

def to_mobilenet(x):
    x = tf.image.grayscale_to_rgb(x)
    x = tf.image.resize(x, [TARGET, TARGET])
    x = mb_pre(x * 255.0)  # MobileNetV2 expects [-1,1] after this
    return x

def make_ds(X, y=None, batch=32, shuffle=False):
    ds = tf.data.Dataset.from_tensor_slices((X, y) if y is not None else (X,))
    if shuffle: ds = ds.shuffle(8192)
    ds = ds.map(lambda *z: (to_mobilenet(z[0]), z[1]) if y is not None else (to_mobilenet(z[0]),),
                num_parallel_calls=tf.data.AUTOTUNE)
    ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)
    return ds

# Build model
base = MobileNetV2(input_shape=(TARGET, TARGET, 3), include_top=False, weights="imagenet")
base.trainable = False  # freeze

x = base.output
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.2)(x)
out = layers.Dense(NUM_CLASSES, activation="softmax", dtype="float32")(x)

model = models.Model(inputs=base.input, outputs=out)
model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# ‚úÖ callbacks (add checkpoint here)
early  = EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)
reduce = ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=2, min_lr=1e-6)
ckpt   = ModelCheckpoint(
    "mobilenetv2_baseline.keras",   # file to save
    monitor="val_accuracy",         # save the best by validation accuracy
    mode="max",
    save_best_only=True,
    verbose=1
)

# Datasets
train_ds = make_ds(X_train_cnn, y_train, batch=32, shuffle=True)
val_ds   = make_ds(X_val_cnn,   y_val,   batch=32)
test_ds  = make_ds(X_test_cnn,  y_test,  batch=32)

# Train  ‚úÖ include ckpt in callbacks
history = model.fit(train_ds, epochs=30, validation_data=val_ds, callbacks=[early, reduce, ckpt], verbose=1)

# ‚úÖ (recommended) reload the best checkpoint BEFORE test/evaluation & fine-tuning
model = tf.keras.models.load_model("mobilenetv2_baseline.keras")

# Optional: also save the final-in-RAM model if you want both
# model.save("mobilenetv2_baseline_final.keras")

# Evaluate
test_loss, test_acc = model.evaluate(test_ds, verbose=0)
print("Test acc:", test_acc)

# === PLOT: training curves ===
import matplotlib.pyplot as plt

hist = history.history
epochs = range(1, len(hist["loss"]) + 1)

plt.figure(figsize=(12,4))

# Accuracy
plt.subplot(1,2,1)
plt.plot(epochs, hist["accuracy"],     marker="o", label="Train")
plt.plot(epochs, hist["val_accuracy"], marker="o", label="Val")
plt.title("Accuracy"); plt.xlabel("Epoch"); plt.ylabel("Accuracy")
plt.grid(True); plt.legend()

# Loss
plt.subplot(1,2,2)
plt.plot(epochs, hist["loss"],     marker="o", label="Train")
plt.plot(epochs, hist["val_loss"], marker="o", label="Val")
plt.title("Loss"); plt.xlabel("Epoch"); plt.ylabel("Loss")
plt.grid(True); plt.legend()

plt.tight_layout(); plt.show()

# === REPORT + CONFUSION MATRICES  ===
import numpy as np, string
import matplotlib.pyplot as plt, seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix

# Predictions
y_true = np.concatenate([y for _, y in test_ds], axis=0)
y_pred = np.argmax(model.predict(test_ds, verbose=0), axis=1)

# Class names A..Z
class_names = list(string.ascii_uppercase)

# Classification report
print("\nClassification Report (A‚ÄìZ):")
print(classification_report(
    y_true, y_pred,
    labels=range(len(class_names)),
    target_names=class_names,
    digits=4
))

# Confusion matrices
cm  = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))
cmn = cm / cm.sum(axis=1, keepdims=True)

fig, axes = plt.subplots(1, 2, figsize=(15, 6))

sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=class_names, yticklabels=class_names, ax=axes[0])
axes[0].set_title("Confusion Matrix (counts)")
axes[0].set_xlabel("Predicted"); axes[0].set_ylabel("True")

sns.heatmap(cmn, annot=False, cmap="Blues",
            xticklabels=class_names, yticklabels=class_names, vmin=0, vmax=1, ax=axes[1])
axes[1].set_title("Confusion Matrix (row-normalized)")
axes[1].set_xlabel("Predicted"); axes[1].set_ylabel("True")

plt.tight_layout(); plt.show()

"""The pretrained MobileNetV2 (trained on ImageNet) was used as a frozen feature extractor, with only a new dense classifier head trained on the alphabet dataset.
Result: The frozen MobileNetV2 achieved solid accuracy but did not outperform the best CNN, since only the top layers were trained. It showed efficiency but lacked fine-tuned adaptation to handwriting

## 6. Fine-Tuned MobileNetV2
"""

# ============================
# Block 1 ‚Äî Fine-tune baseline
# ============================
import tensorflow as tf
from tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling2D
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint

# assumes train_ds / val_ds already exist
model = tf.keras.models.load_model("mobilenetv2_baseline.keras")

UNFREEZE = 40  # number of backbone layers to unfreeze

# --- Try to get a nested MobilenetV2 submodel ---
base = None
for lyr in model.layers:
    if isinstance(lyr, tf.keras.Model) and "mobilenetv2" in lyr.name.lower():
        base = lyr
        break

if base is not None:
    # Case A: nested backbone exists
    print(f"Backbone (nested) found: {base.name} | sublayers: {len(base.layers)}")
    # freeze all
    for lyr in base.layers: lyr.trainable = False
    # unfreeze top-N except BatchNorm
    for lyr in base.layers[-min(UNFREEZE, len(base.layers)):]:
        if not isinstance(lyr, BatchNormalization):
            lyr.trainable = True
else:
    # Case B: backbone is flattened into the top model
    layers_list = model.layers
    # find the GAP layer that starts the head
    gap_idx = next(i for i, L in enumerate(layers_list) if isinstance(L, GlobalAveragePooling2D))
    backbone_layers = layers_list[:gap_idx]
    head_layers     = layers_list[gap_idx:]

    print(f"Flattened backbone detected. Backbone layers: {len(backbone_layers)}, head layers: {len(head_layers)}")

    # freeze everything first
    for L in layers_list: L.trainable = False
    # keep head trainable
    for L in head_layers: L.trainable = True
    # unfreeze top-N backbone layers (skip BatchNorm)
    trainable_backbone = [L for L in backbone_layers if not isinstance(L, BatchNormalization)]
    for L in trainable_backbone[-min(UNFREEZE, len(trainable_backbone)):]:
        L.trainable = True

# compile with low LR and train
model.compile(optimizer=tf.keras.optimizers.Adam(5e-5),
              loss="sparse_categorical_crossentropy",
              metrics=["accuracy"])

early  = EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True, verbose=1)
reduce = ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=2, min_lr=1e-6, verbose=1)
ckptft = ModelCheckpoint("mobilenetv2_finetuned.keras",
                         monitor="val_accuracy", mode="max",
                         save_best_only=True, verbose=1)

history_ft = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=20,
    callbacks=[early, reduce, ckptft],
    verbose=1
)

# === PLOT ONLY: training vs validation curves ===
import matplotlib.pyplot as plt

hist = history_ft.history  # from your fine-tuning fit(...)
epochs = range(1, len(hist["loss"]) + 1)

plt.figure(figsize=(12,4))

# Accuracy
plt.subplot(1,2,1)
plt.plot(epochs, hist["accuracy"],     marker="o", label="Train")
plt.plot(epochs, hist["val_accuracy"], marker="o", label="Val")
plt.title("Accuracy"); plt.xlabel("Epoch"); plt.ylabel("Accuracy")
plt.grid(True); plt.legend()

# Loss
plt.subplot(1,2,2)
plt.plot(epochs, hist["loss"],     marker="o", label="Train")
plt.plot(epochs, hist["val_loss"], marker="o", label="Val")
plt.title("Loss"); plt.xlabel("Epoch"); plt.ylabel("Loss")
plt.grid(True); plt.legend()

plt.tight_layout(); plt.show()

# ===============================================================
# Block 2 ‚Äî Evaluate + classification report + confusion matrices
# ===============================================================
import tensorflow as tf, numpy as np, string
import matplotlib.pyplot as plt, seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix

# assumes test_ds exists
best_ft = tf.keras.models.load_model("mobilenetv2_finetuned.keras")

# Evaluate
test_loss, test_acc = best_ft.evaluate(test_ds, verbose=0)
print(f"Fine-tuned Test Accuracy (best ckpt): {test_acc:.4f} | Loss: {test_loss:.4f}")

# Predictions
y_true = np.concatenate([y for _, y in test_ds], axis=0)
y_pred = np.argmax(best_ft.predict(test_ds, verbose=0), axis=1)

# Classification report
class_names = list(string.ascii_uppercase)
print("\nClassification Report (A‚ÄìZ):")
print(classification_report(
    y_true, y_pred,
    labels=range(len(class_names)),
    target_names=class_names,
    digits=4
))

# Confusion matrices (counts + normalized)
cm  = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))
cmn = cm / cm.sum(axis=1, keepdims=True)

fig, axes = plt.subplots(1, 2, figsize=(15, 6))

sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=class_names, yticklabels=class_names, ax=axes[0])
axes[0].set_title("Confusion Matrix (counts)")
axes[0].set_xlabel("Predicted"); axes[0].set_ylabel("True")

sns.heatmap(cmn, annot=False, cmap="Blues", vmin=0, vmax=1,
            xticklabels=class_names, yticklabels=class_names, ax=axes[1])
axes[1].set_title("Confusion Matrix (row-normalized)")
axes[1].set_xlabel("Predicted"); axes[1].set_ylabel("True")

plt.tight_layout(); plt.show()

"""The baseline MobileNetV2 was further fine-tuned by unfreezing the top 40 layers and training them on the dataset with a low learning rate.
Result: This fine-tuned version improved performance compared to the frozen baseline, as it adapted the pretrained weights to handwriting features. It reached competitive accuracy with CNN-based models

deep_learning25_last_one (1)

.
"""

# ============================================================
# Save model + history + metadata (NO retraining)
# ============================================================
import os, json
import tensorflow as tf

SAVE_DIR = "/content/drive/MyDrive/AZ_MBV2"   # change if not using Colab/Drive
os.makedirs(SAVE_DIR, exist_ok=True)

# ---- Save best model currently in RAM ----
best_model_path = os.path.join(SAVE_DIR, "mobilenetv2_finetuned.keras")
model.save(best_model_path)
print(f"‚úÖ Saved model to: {best_model_path}")

# ---- Save training history ----
with open(os.path.join(SAVE_DIR, "history_ft.json"), "w") as f:
    json.dump({k: [float(x) for x in v] for k, v in history_ft.history.items()}, f)
print("‚úÖ Saved training history to history_ft.json")

# ---- Save metadata ----
meta = {
    "num_classes": 26,
    "image_size": 96,
    "backbone": "MobileNetV2",
    "preprocess": "mobilenet_v2.preprocess_input",
    "notes": "Fine-tuned top ~40 layers; EarlyStopping + ReduceLROnPlateau; best on val_accuracy.",
    "alphabet": [chr(i) for i in range(65, 91)]  # A-Z
}
with open(os.path.join(SAVE_DIR, "meta.json"), "w") as f:
    json.dump(meta, f, indent=2)
print("‚úÖ Saved metadata to meta.json")

"""## 7. MobileNetV2 with Hyperparameter Tuning"""

!pip install -q keras-tuner

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mb_pre
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
import keras_tuner as kt
import os, json

"""## Dataset Helper for MobileNetV2 (CPU-safe)"""

def to_mobilenet(x):
    x = tf.image.grayscale_to_rgb(x)                      # from (28,28,1) to (28,28,3)
    x = tf.image.resize(x, [96, 96])                      # resize to MobileNetV2 input
    x = mb_pre(x * 255.0)                                 # scale back and preprocess
    return x

def make_ds(X, y=None, batch=32, shuffle=False):
    ds = tf.data.Dataset.from_tensor_slices((X, y) if y is not None else (X,))
    if shuffle: ds = ds.shuffle(2048)
    ds = ds.map(lambda *z: (to_mobilenet(z[0]), z[1]) if y is not None else (to_mobilenet(z[0]),),
                num_parallel_calls=tf.data.AUTOTUNE)
    ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)
    return ds

# Prepare datasets from your processed numpy arrays (X_train_cnn, y_train, etc.)
train_ds = make_ds(X_train_cnn, y_train, batch=32, shuffle=True)
val_ds   = make_ds(X_val_cnn,   y_val, batch=32)
test_ds  = make_ds(X_test_cnn,  y_test, batch=32)

"""## Model Builder"""

def build_finetuned_mbv2(hp):
    base = MobileNetV2(include_top=False, weights='imagenet', input_shape=(96, 96, 3))
    base.trainable = True

    # Unfreeze only top N layers
    UNFREEZE = hp.Choice('unfreeze_layers', [20, 40])  # smaller options for CPU
    for layer in base.layers[:-UNFREEZE]:
        layer.trainable = False
    for layer in base.layers[-UNFREEZE:]:
        if not isinstance(layer, tf.keras.layers.BatchNormalization):
            layer.trainable = True

    model = models.Sequential([
        base,
        layers.GlobalAveragePooling2D(),
        layers.Dropout(hp.Float('dropout_rate', 0.3, 0.5, step=0.1)),
        layers.Dense(hp.Int('dense_units', 64, 128, step=64), activation='relu'),
        layers.Dropout(hp.Float('dropout_fc', 0.4, 0.6, step=0.1)),
        layers.Dense(26, activation='softmax')
    ])

    model.compile(
        optimizer=tf.keras.optimizers.Adam(hp.Choice('lr', [1e-3, 1e-4])),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

"""## Tuner Setup + Callbacks + Search (Optimized)"""

SAVE_DIR = "/content/drive/MyDrive/AZ_MBV2_HPO"
os.makedirs(SAVE_DIR, exist_ok=True)

tuner = kt.RandomSearch(
    build_finetuned_mbv2,
    objective='val_accuracy',
    max_trials=5,                        # reduced for speed
    directory='tuner_finetune',
    project_name='mobilenetv2_cpu'
)

early_stop = EarlyStopping(monitor="val_loss", patience=2, restore_best_weights=True)
reduce_lr  = ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=1, verbose=1)
checkpoint = ModelCheckpoint(
    filepath=os.path.join(SAVE_DIR, "mobilenetv2_best_cpu.keras"),
    monitor="val_accuracy", mode="max", save_best_only=True, verbose=1
)

tuner.search(
    train_ds,
    validation_data=val_ds,
    epochs=15,
    callbacks=[early_stop, reduce_lr, checkpoint],
    verbose=1
)

"""## Save Best Model, History & Metadata"""

# Get best model & hyperparameters
best_model = tuner.get_best_models(1)[0]
best_hps = tuner.get_best_hyperparameters(1)[0]

# Retrain for history (few epochs)
history = best_model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=10,
    callbacks=[early_stop, reduce_lr],
    verbose=1
)

# Save history
with open(os.path.join(SAVE_DIR, "history_tuned.json"), "w") as f:
    json.dump({k: list(map(float, v)) for k, v in history.history.items()}, f)

# Save metadata
metadata = {
    "unfreeze_layers": best_hps.get('unfreeze_layers'),
    "dropout_rate": best_hps.get('dropout_rate'),
    "dense_units": best_hps.get('dense_units'),
    "dropout_fc": best_hps.get('dropout_fc'),
    "lr": best_hps.get('lr'),
    "input_size": 96,
    "backbone": "MobileNetV2",
    "note": "Fine-tuned MBV2 with Keras Tuner (CPU-friendly)"
}
with open(os.path.join(SAVE_DIR, "metadata_tuned.json"), "w") as f:
    json.dump(metadata, f, indent=2)

print("‚úÖ Model, history, and metadata saved to:", SAVE_DIR)

"""## Plot Accuracy & Loss Curves"""

import matplotlib.pyplot as plt

# üìä Plotting function
def plot_history(history):
    hist = history.history
    epochs = range(1, len(hist["accuracy"]) + 1)

    plt.figure(figsize=(12, 4))

    # Accuracy
    plt.subplot(1, 2, 1)
    plt.plot(epochs, hist["accuracy"], label="Train Accuracy", marker="o")
    plt.plot(epochs, hist["val_accuracy"], label="Val Accuracy", marker="o")
    plt.title("Accuracy")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.grid(True)
    plt.legend()

    # Loss
    plt.subplot(1, 2, 2)
    plt.plot(epochs, hist["loss"], label="Train Loss", marker="o")
    plt.plot(epochs, hist["val_loss"], label="Val Loss", marker="o")
    plt.title("Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.grid(True)
    plt.legend()

    plt.tight_layout()
    plt.show()

# üñºÔ∏è Call the plot function
plot_history(history)

"""## Classification Report + Confusion Matrix"""

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
import seaborn as sns
import string

# üìå Predict on test set
y_true = np.concatenate([y for _, y in test_ds], axis=0)
y_pred_probs = best_model.predict(test_ds, verbose=0)
y_pred = np.argmax(y_pred_probs, axis=1)

# üìù Classification report
print("üìã Classification Report (A‚ÄìZ):\n")
class_labels = list(string.ascii_uppercase)
print(classification_report(
    y_true,
    y_pred,
    labels=range(26),
    target_names=class_labels,
    digits=4
))

"""## Confusion Matrix (Counts + Normalized)"""

# üî≤ Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
cmn = cm / cm.sum(axis=1, keepdims=True)  # row-normalized

# üìä Plot both confusion matrices
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Raw counts
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=class_labels, yticklabels=class_labels, ax=axes[0])
axes[0].set_title("Confusion Matrix (Counts)")
axes[0].set_xlabel("Predicted Label")
axes[0].set_ylabel("True Label")

# Normalized
sns.heatmap(cmn, annot=False, cmap="Blues", vmin=0, vmax=1,
            xticklabels=class_labels, yticklabels=class_labels, ax=axes[1])
axes[1].set_title("Confusion Matrix (Normalized)")
axes[1].set_xlabel("Predicted Label")
axes[1].set_ylabel("True Label")

plt.tight_layout()
plt.show()

"""Keras Tuner was applied to MobileNetV2 to optimize dropout, dense units, and learning rates. The best configuration was then retrained and evaluated.
Result: The tuned MobileNetV2 achieved the highest accuracy among all MobileNet models, but performance gains were not drastic. It showed that transfer learning combined with tuning can yield efficient and accurate recognition

"""

# Get the best model from tuner
best_model = tuner.get_best_models(1)[0]

# Save it where you want (e.g., sample_data or Drive)
SAVE_DIR = "/content/sample_data"
best_model.save(os.path.join(SAVE_DIR, "best_tuned_model.keras"))

print("‚úÖ Best tuned model saved at:", os.path.join(SAVE_DIR, "best_tuned_model.keras"))

"""## Model Testing on Random Sample Images"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf # Import tensorflow

# === Pick 5 random samples from test set ===
for images, labels in test_ds.take(1):   # take one batch from test_ds
    # Convert tensors to NumPy arrays for easier indexing
    images_np = images.numpy()
    labels_np = labels.numpy()

    idxs = np.random.choice(range(len(images_np)), 5, replace=False)
    sample_images = images_np[idxs]
    sample_labels = labels_np[idxs]

# === Make predictions ===
# Need to convert back to tensor for prediction
pred_probs = best_model.predict(tf.convert_to_tensor(sample_images, dtype=tf.float32))
pred_classes = np.argmax(pred_probs, axis=1)

# === Plot results ===
plt.figure(figsize=(12, 6))
for i in range(5):
    plt.subplot(1, 5, i+1)
    # Ensure image is in correct format for imshow (uint8)
    # Depending on preprocessing, you might need to scale it back to 0-255
    # Assuming MobileNetV2 preprocess_input was used, output is [-1, 1], need to reverse
    img_display = ((sample_images[i] + 1) / 2.0) * 255.0 # Simple reversal example, adjust if needed
    plt.imshow(img_display.astype("uint8"))
    plt.title(f"True: {sample_labels[i]}\nPred: {pred_classes[i]}")
    plt.axis("off")
plt.show()

"""## Model Architecture Diagram"""

!pip install visualkeras

import visualkeras
from tensorflow import keras
from PIL import ImageFont

# Load model
model = keras.models.load_model("/content/mobilenetv2_finetuned_with_tunning.keras")

# Optional: font for labels
try:
    font = ImageFont.truetype("DejaVuSans.ttf", 32)  # works in Colab
except:
    font = None

# Create the architecture diagram
img = visualkeras.layered_view(
    model,
    legend=True,
    draw_volume=True,
    font=font
)

# Show directly in Colab
display(img)

# Save to file
img.save("mobilenetv2_finetuned_architecture_with_tunning.png")

"""## 8. Rebuild the Best Tuned Model (MobileNetV2)"""

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.optimizers import Adam

# ==== Best Hyperparameters from HPO ====
best_hps = {
    'unfreeze_layers': 40,
    'dropout_rate': 0.5,
    'dense_units': 64,
    'dropout_fc': 0.5,
    'lr': 0.001
}
NUM_CLASSES = 26  # Adjust if needed

# ==== Build Model ====
def build_best_mbv2_model(hp_dict):
    base = MobileNetV2(include_top=False, weights='imagenet', input_shape=(96, 96, 3))
    base.trainable = True

    # Freeze all layers except the top N
    for layer in base.layers[:-hp_dict['unfreeze_layers']]:
        layer.trainable = False
    for layer in base.layers[-hp_dict['unfreeze_layers']:]:
        if not isinstance(layer, tf.keras.layers.BatchNormalization):
            layer.trainable = True

    model = models.Sequential([
        base,
        layers.GlobalAveragePooling2D(),
        layers.Dropout(hp_dict['dropout_rate']),
        layers.Dense(hp_dict['dense_units'], activation='relu'),
        layers.Dropout(hp_dict['dropout_fc']),
        layers.Dense(NUM_CLASSES, activation='softmax')
    ])

    model.compile(
        optimizer=Adam(learning_rate=hp_dict['lr']),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )

    return model

# ==== Create Model ====
best_model = build_best_mbv2_model(best_hps)
best_model.summary()

from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# Define the callbacks
early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)

history = best_model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=20,
    callbacks=[early_stop, reduce_lr],
    verbose=1
)

import matplotlib.pyplot as plt

# === Plot Accuracy ===
plt.figure(figsize=(8, 5))
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

# === Plot Loss ===
plt.figure(figsize=(8, 5))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

# Get true labels and predicted labels
y_true = []
y_pred = []

for images, labels in test_ds:
    preds = best_model.predict(images)
    y_true.extend(labels.numpy())
    y_pred.extend(np.argmax(preds, axis=1))

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.show()

# Classification Report
print("Classification Report:")
print(classification_report(y_true, y_pred, digits=4))

"""In this step, the MobileNetV2 model was rebuilt using the best hyperparameters obtained from Keras Tuner (unfreezing 40 layers, dropout of 0.5, dense units of 64, and learning rate of 0.001). The model was then retrained and evaluated on validation and test sets.
Result: This final tuned MobileNetV2 achieved the best balance of accuracy and generalization among all transfer learning models. While its accuracy was close to the fine-tuned MobileNetV2, the use of optimized hyperparameters provided more stable training and improved consistency in predictions
"""

# Save the entire model
model.save("mobilenetv2_final.keras")